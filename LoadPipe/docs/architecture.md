# LoadPipe 

Цей документ пояснює **що робить кожен модуль**, **як вони з’єднані** між собою та **як рухаються дані**. Мета — щоб ви могли швидко розібратися і безпечно запустити або змінити пайплайн.

---

## Ідея 

**LoadPipe** — це «труба» для великих файлів: беремо файл з Google Drive **частинами (чанками)**, **обробляємо потоком** (без повного зберігання на диск/у RAM) і **заливаємо результат назад**, з можливістю **відновлення після збоїв**.

---

## Як уявляти систему (ментальна модель)

```
[Google Drive] --(скачування частинами)--> [Download] --(потік байтів)--> [Processing] --(потік байтів)--> [Upload] --> [Google Drive]
                                             \__________________________ Контроль прогресу (Manifest) __________________________/
```

* **Source**: Google Drive (файли у папках).
* **Download**: забираємо **частинами**, щоб не переповнювати диск/пам’ять.
* **Processing**: перетворюємо «на льоту» (поки що місце для ваших процесорів).
* **Upload**: відправляємо результат на Drive **частинами** (resumable).
* **Manifest (стан)**: база, де зберігаємо прогрес, щоб **продовжити з місця зупинки**.

---

## 3) Модулі по черзі — просто і коротко

Нижче — те, що є в `src/`, і простими словами, для чого це потрібно.

### 3.1 `cli.py` — Командний інтерфейс

* **Що робить:** приймає команди користувача (наприклад, `list`, `pull`, `push`, `sync`), перевіряє аргументи, викликає потрібні модулі.
* **Взаємодія:** читає конфіг (`config.py`), викликає `auth`, `adapters.gdrive`, `io.download`, `io.upload`, оновлює `state.manifest`, пише логи через `log.py`.

### 3.2 `config.py` — Налаштування проєкту

* **Що робить:** читає `configs/config.yaml`, перевіряє валідність (ID папок, розмір чанка тощо), перетворює в зручні Python-об’єкти.
* **Взаємодія:** використовується `cli.py` і будь-якими місцями, де потрібні параметри (розміри чанків, ліміти кешу).

### 3.3 `log.py` — Логи

* **Що робить:** уніфікований запис подій і метрик (скільки байтів пройшло, скільки було повторів/помилок).
* **Взаємодія:** його викликають усі частини, щоб бачити прогрес і розслідувати проблеми.

### 3.4 `errors.py` — Помилки

* **Що робить:** набор іменованих винятків (наприклад, `AuthError`, `ResumeMismatchError`) для зрозумілих повідомлень.
* **Взаємодія:** піднімаються всередині модулів, обробляються у `cli.py`.

### 3.5 `auth/` — Авторизація

* **`oauth.py`**: отримання/оновлення токенів для Google API (локальний вхід через браузер).
* **Взаємодія:** постачає «клієнта з правами» для `adapters/gdrive.py`.

### 3.6 `adapters/` — Драйвери доступу до сховищ

* **`gdrive.py`**: один «вхід» до Google Drive.

  * `list_files(folder_id, pattern)`: отримати список файлів.
  * `stat(file_id)`: дізнатися розмір/час зміни/хеш.
  * `download_range(file_id, start, end)`: скачати шматок (діапазон байтів).
  * `begin_resumable_upload(...)` + `upload_chunk(...)`: шматкове завантаження назад.
* **Взаємодія:** працює з `auth/` для доступу; його використовують `io/download.py` і `io/upload.py`.

### 3.7 `io/` — Ввід/вивід та файлові утиліти

* **`download.py`**: головна функція **потокового скачування з відновленням**:

  * ділить файл на чанки, докачує з місця зупинки,
  * оновлює прогрес у `state/manifest.py`,
  * за потреби кладе тимчасові дані в кеш (`cache/lru.py`).
* **`upload.py`**: **потокове завантаження** назад на Drive:

  * відкриває/відновлює сесію завантаження,
  * шле чанки, доки все не залиється.
* **`fs.py`**: дрібні речі: атомічні записи, створення тимчасових файлів.
* **Взаємодія:** `download`/`upload` напряму викликають `adapters.gdrive`, зберігають прогрес у `state/manifest`, можуть використовувати `cache.lru`.

### 3.8 `processing/` — Обробка даних (плейсхолдер)

* **Поки що тут тільки `__init__.py`**. Ідея така:

  * ви додаєте свої функції-«процесори», що беруть **потік байтів** і повертають **потік байтів/рядків**.
  * приклади майбутніх процесорів: розпаковка `.zst`, фільтрація рядків, маппінг JSON тощо.
* **Взаємодія:** стоїть **між** `download` і `upload` у загальному ланцюжку.

### 3.9 `cache/` — Кеш на диск

* **`lru.py`**: контролює, щоб кеш не перевищував ліміт (наприклад, 30 ГБ). Видаляє старе, якщо місця бракує.
* **Взаємодія:** використовується `io/download` (і потенційно процесорами), щоб економити RAM.

### 3.10 `state/` — Маніфест прогресу

* **`manifest.py`**: записує і читає прогрес у SQLite:

  * скільки байтів уже скачано/завантажено,
  * які були ETag/modifiedTime у файлу (щоб виявити зміну файлу),
  * історія запусків (опціонально).
* **`schema.sql`**: структура таблиць для SQLite.
* **Взаємодія:** `download`/`upload` регулярно оновлюють маніфест; `cli.py` читає стан для ідемпотентності.

### 3.11 `utils/` — Допоміжні інструменти

* **`retry.py`**: повтори з паузами (exponential backoff) для нестабільної мережі/квот.
* **`hashing.py`**: підрахунок хешів «на льоту», щоб перевіряти цілісність без навантаження пам’яті.
* **Взаємодія:** викликається з `io/` та `adapters/`.

---

## 4) Як модулі пов’язані (картина зверху)

```
[CLI] → читає configs/config.yaml → [config]
  │
  ├─ викликає → [auth/oauth] → токени для Google API
  ├─ викликає → [adapters/gdrive] → list/stat
  ├─ для кожного файлу:
  │     └→ [io/download] → Iterator[bytes]
  │            │
  │            └→ (опційно) [processing/*] → Iterator[bytes/lines]
  │                        │
  │                        └→ [io/upload] → [adapters/gdrive]
  │
  ├─ оновлює стан у → [state/manifest]
  └─ пише події у → [log]
```

Ключові ідеї:

* **CLI** «склеює» блоки та реалізує сценарії.
* **Adapters** ховають специфіку API (Google Drive).
* **IO** гарантує **потоковість і відновлення**.
* **Manifest** зберігає прогрес — це основа для **resume** та **ідемпотентності**.
* **Processing** — місце, де ви додаєте свою бізнес-логіку перетворення даних.

---

## 5) Потік даних — крок за кроком

### Варіант A: «трубою» через CLI

```
(1) lp list --folder SRC   → показати вхідні файли
(2) lp pull --file FILE_ID → завантажуємо байти порціями
(3) | (опціонально) ваш процесор  → змінюємо потік байтів/рядків
(4) | lp push --folder DST --name out.jsonl → заливаємо результат порціями
```

### Варіант B: один конфіг — весь цикл

```
lp sync --config configs/config.yaml
```

LoadPipe сам:

1. Знаходить файли-джерела (через `adapters/gdrive`).
2. Для кожного файла піднімає `download` з **resume** (дивиться в `state/manifest`).
3. (Опційно) Пропускає потік через `processing/*`.
4. Віддає потік у `upload` з **resume**.
5. Логує події і оновлює `manifest`.

---

## 6) Що таке «маніфест» і навіщо він

* Це «чорний ящик» з прогресом: **на якому байті зупинилися**, коли і з якими параметрами.
* Якщо файл змінився на Drive (інша мітка часу/ETag), `manifest` допоможе **виявити конфлікт** і не «доклеїти» дані до іншого вмісту.
* Завдяки `manifest` повторний запуск команди **не створює дублікати** і продовжує роботу «з того ж місця».

---

## 7) Як система поводиться при збоях

* **Мережеві збої / 429 / 5xx** → `utils/retry.py` робить повтор з паузою (exponential backoff).
* **Обрив на середині скачування** → `io/download` читає останній байт з `manifest` і **докачує** далі.
* **Обрив під час завантаження** → `io/upload` відновлює **resumable**-сесію і **досилає** з потрібного місця.
* **Мало місця на диску** → `cache/lru` видаляє старі тимчасові файли, щоб вписатися в ліміт.

---

## 8) Де що лежить поза `src/`

* `configs/` — тут ваші YAML-конфіги (що, звідки і куди тягнути, розміри чанків тощо).
* `docs/architecture.md` — цей документ.
* `project.toml` — метадані проєкту і залежності.
* `README.md` — короткий опис і швидкий старт.

---

## 9) Словничок (щоб говорити однією мовою)

* **Чанк (chunk)** — шматок файла, який ми завантажуємо/заливаємо за один запит (наприклад, 64 МБ).
* **Потік (stream)** — дані, що йдуть частинами, без повного завантаження в пам’ять.
* **Resumable** — можливість **продовжити** завантаження/скачування з місця зупинки.
* **Manifest** — локальна база зі станом прогресу (SQLite).

---

## 10) Як додати свою обробку (processing)

1. Створіть нову функцію у `src/processing/` (або підпакет), яка:

   * приймає **ітератор байтів/рядків**,
   * повертає **ітератор байтів/рядків**.
2. У `cli.py` додайте опцію, щоб можна було вставити ваш процесор у «трубу».
3. Тримайте все **потоковим**: не тримайте увесь файл у пам’яті.

---

### TL;DR

* **LoadPipe = конвеєр:** Drive → (скачати частинами) → (обробити потоком) → (залити частинами) → Drive.
* **Manifest** = відновлення + ідемпотентність.
* **CLI** склеює модулі; **adapters** ховають API; **io** рухає байти; **processing** — місце для вашої логіки.
* Все спроєктовано так, щоб **економити пам’ять/диск** і **не ламатися** при обривах.
