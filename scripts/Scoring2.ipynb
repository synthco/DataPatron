{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-29T13:30:44.184500Z",
     "start_time": "2025-11-29T13:30:39.908752Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot styling configuration\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "print(\"✅ Libraries imported successfully.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivantyshchenko/Projects/Python/DataPatron/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:32:00.687458Z",
     "start_time": "2025-11-29T13:32:00.679905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AdvancedMessageMetrics:\n",
    "    def __init__(self):\n",
    "        print(\"⏳ Loading Sentiment Model (XLM-RoBERTa)...\")\n",
    "        # Using CPU (device=-1). If you have a GPU, change to device=0\n",
    "        self.sentiment_pipe = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "            tokenizer=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "            top_k=None,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            device=\"mps\"\n",
    "        )\n",
    "\n",
    "        print(\"⏳ Loading Toxicity Model (Multilingual Toxic XLM-R)...\")\n",
    "        self.toxic_pipe = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"unitary/multilingual-toxic-xlm-roberta\",\n",
    "            tokenizer=\"unitary/multilingual-toxic-xlm-roberta\",\n",
    "            top_k=None,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            device=-1\n",
    "        )\n",
    "        print(\"✅ Models loaded!\")\n",
    "\n",
    "    def _get_sentiment_score(self, text):\n",
    "        \"\"\"Converts model output into a number from -1.0 (Negative) to 1.0 (Positive).\"\"\"\n",
    "        try:\n",
    "            results = self.sentiment_pipe(text)[0]\n",
    "            scores = {item['label'].lower(): item['score'] for item in results}\n",
    "\n",
    "            # Normalize label names (sometimes models return label_0/1/2)\n",
    "            if 'label_0' in scores:\n",
    "                scores['negative'] = scores.pop('label_0')\n",
    "                scores['neutral'] = scores.pop('label_1')\n",
    "                scores['positive'] = scores.pop('label_2')\n",
    "\n",
    "            # Formula: Positive minus Negative\n",
    "            return scores.get('positive', 0.0) - scores.get('negative', 0.0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sentiment: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "    def _get_toxicity_score(self, text):\n",
    "        \"\"\"Returns toxicity probability (0.0 - 1.0).\"\"\"\n",
    "        try:\n",
    "            results = self.toxic_pipe(text)[0]\n",
    "            scores = {item['label']: item['score'] for item in results}\n",
    "            # We take the general 'toxic' score\n",
    "            return scores.get('toxic', 0.0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in toxicity: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "    def calculate_ucqs(self, comments_content):\n",
    "        \"\"\"\n",
    "        Calculates Unified Comment Quality Score (UCQS).\n",
    "        Input: List of comment texts or string representation of a list.\n",
    "        Output: Float 0-100.\n",
    "        \"\"\"\n",
    "        # 1. Validation and parsing of input data\n",
    "        if isinstance(comments_content, str):\n",
    "            try:\n",
    "                comments_content = ast.literal_eval(comments_content)\n",
    "            except:\n",
    "                return 50.0 # Return neutral baseline on parse error\n",
    "\n",
    "        if not isinstance(comments_content, list) or not comments_content:\n",
    "            return 50.0\n",
    "\n",
    "        sentiments = []\n",
    "        toxicity_scores = []\n",
    "\n",
    "        # 2. Analyze each comment\n",
    "        for text in comments_content:\n",
    "            if not isinstance(text, str) or not text.strip():\n",
    "                continue\n",
    "\n",
    "            # Truncate to 512 chars for speed\n",
    "            short_text = text[:512]\n",
    "\n",
    "            sentiments.append(self._get_sentiment_score(short_text))\n",
    "            toxicity_scores.append(self._get_toxicity_score(short_text))\n",
    "\n",
    "        if not sentiments:\n",
    "            return 50.0\n",
    "\n",
    "        # 3. Aggregating statistics\n",
    "        s_avg = np.mean(sentiments)      # Average sentiment (-1..1)\n",
    "        s_var = np.std(sentiments)       # Sentiment variance (0..1)\n",
    "        t_avg = np.mean(toxicity_scores) # Average toxicity (0..1)\n",
    "\n",
    "        # 4. Final UCQS Formula\n",
    "        # Base 50 + (Sentiment * 40) - (Variance * 20) - (Toxicity * 30)\n",
    "        ucqs = 50 + (s_avg * 40) - (s_var * 20) - (t_avg * 30)\n",
    "\n",
    "        return float(np.clip(ucqs, 0, 100))\n",
    "\n",
    "    def calculate_efficiency(self, score, num_comments, upvote_ratio):\n",
    "        \"\"\"Calculates Adjusted Efficiency Score (Virality).\"\"\"\n",
    "        # Handle null values\n",
    "        score = score if pd.notnull(score) else 0\n",
    "        comments = num_comments if pd.notnull(num_comments) else 0\n",
    "        ratio = upvote_ratio if pd.notnull(upvote_ratio) else 0.5\n",
    "\n",
    "        # Comments are weighted higher (x2) as they require more effort\n",
    "        raw_engagement = score + (comments * 2.0)\n",
    "\n",
    "        # Logarithm smooths out outliers (million-view posts)\n",
    "        log_engagement = np.log1p(raw_engagement)\n",
    "\n",
    "        return round(log_engagement * ratio, 2)"
   ],
   "id": "b64cf62d8f564be3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-29T13:32:01.719001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"/Users/ivantyshchenko/Projects/Python/DataPatron/data/reddit.csv\")\n",
    "metrics_engine = AdvancedMessageMetrics()\n",
    "\n",
    "df['Efficiency'] = df.apply(\n",
    "    lambda x: metrics_engine.calculate_efficiency(\n",
    "        x['score'], x['num_comments'], x['upvote_ratio']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# 2. Calculate UCQS (this may take time depending on the number of comments)\n",
    "df['UCQS'] = df['comments_content'].apply(metrics_engine.calculate_ucqs)\n"
   ],
   "id": "4cbe5be7cd1266d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading Sentiment Model (XLM-RoBERTa)...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "baab852a383b658c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
